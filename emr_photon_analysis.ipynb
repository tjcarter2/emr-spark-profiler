{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a60d1bb-706e-49e6-8f2b-f735826597c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Photon Compatibility Analysis\n",
    "This cell analyzes the `sql_df` DataFrame to identify how much of a Spark application's workload can be accelerated by Photon.\n",
    "It parses the JSON query plans, flags compatible operations, and calculates a \"Photon Compatibility Score\" for each application.\n",
    "A higher score indicates a greater portion of the application's SQL workload is Photon-compatible, suggesting better performance. A low score highlights opportunities for optimization by refactoring non-compatible operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62757088-041d-4ef6-8f07-cd8f08df3771",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_json, explode, when, count, avg\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# A list of common Spark plan operations that are NOT accelerated by Photon.\n",
    "# This list can be extended as needed based on specific workloads.\n",
    "NON_PHOTON_OPERATIONS = [\n",
    "    \"MapElements\",       # Often associated with Scala/Java UDFs\n",
    "    \"MapPartitions\",     # Can be used by various custom operations\n",
    "    \"PythonUDF\",         # Python User-Defined Functions\n",
    "    \"ScalaUDF\",          # Scala User-Defined Functions\n",
    "    \"FlatMapGroupsInPandas\", # Pandas UDFs\n",
    "    \"Scan csv\",          # Photon does not accelerate CSV scans\n",
    "    \"Scan json\"          # Photon does not accelerate JSON scans\n",
    "]\n",
    "\n",
    "# Define the schema to extract the nodeName from the JSON query plan.\n",
    "# We only need the nodeName for this analysis.\n",
    "NODES_SCHEMA = ArrayType(\n",
    "    StructType([\n",
    "        StructField(\"nodeName\", StringType(), True)\n",
    "    ])\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Ensure the required DataFrames exist and are not empty before proceeding.\n",
    "    if 'sql_df' in locals() and sql_df is not None and sql_df.count() > 0 and 'applications_df' in locals() and applications_df is not None:\n",
    "        logger.info(\"\uD83D\uDE80 Starting Photon compatibility analysis...\")\n",
    "        print(\"\uD83D\uDE80 Starting Photon compatibility analysis...\")\n",
    "\n",
    "        # Step 1: Get the application names from the applications_df DataFrame.\n",
    "        # We select distinct rows to avoid any potential duplicates.\n",
    "        app_names_df = applications_df.select(\n",
    "            \"cluster_id\", \"application_id\", \"application_name\"\n",
    "        ).distinct()\n",
    "\n",
    "        # Step 2: Parse the raw JSON, join with app names, and explode the query plan nodes.\n",
    "        # A left join ensures all SQL queries are kept, even if an app name is missing.\n",
    "        exploded_nodes_df = sql_df.join(\n",
    "            app_names_df,\n",
    "            on=[\"cluster_id\", \"application_id\"],\n",
    "            how=\"left\"\n",
    "        ).withColumn(\n",
    "            \"nodes\",\n",
    "            from_json(col(\"sql_raw_json\"), NODES_SCHEMA)\n",
    "        ).select(\n",
    "            \"cluster_id\",\n",
    "            \"cluster_name\",\n",
    "            \"application_id\",\n",
    "            \"application_name\",\n",
    "            \"sql_id\",\n",
    "            explode(col(\"nodes\")).alias(\"node\")\n",
    "        )\n",
    "\n",
    "        # Step 3: Flag operations that are compatible with Photon.\n",
    "        # A new column 'is_photon_op' is added, with 1 for compatible ops.\n",
    "        photon_check_df = exploded_nodes_df.withColumn(\n",
    "            \"is_photon_op\",\n",
    "            when(col(\"node.nodeName\").isin(NON_PHOTON_OPERATIONS), 0).otherwise(1)\n",
    "        )\n",
    "\n",
    "        # Step 4: Calculate the percentage of compatible operations for each application.\n",
    "        # Group by all identifying fields, including the names, to calculate the score.\n",
    "        photon_analysis_df = photon_check_df.groupBy(\n",
    "            \"cluster_id\", \"cluster_name\", \"application_id\", \"application_name\"\n",
    "        ).agg(\n",
    "            (round(avg(col(\"is_photon_op\")) * 100, 2)).alias(\"photon_compatibility_pct\")\n",
    "        ).orderBy(col(\"photon_compatibility_pct\").desc())\n",
    "\n",
    "        logger.info(\"✅ Photon compatibility analysis complete.\")\n",
    "        print(\"✅ Photon compatibility analysis complete.\")\n",
    "        print(\"\uD83D\uDCCA Displaying applications ranked by their Photon Compatibility Score:\")\n",
    "\n",
    "        # Step 5: Display the final results, now including the names.\n",
    "        display(photon_analysis_df)\n",
    "\n",
    "    else:\n",
    "        logger.warning(\"⚠️ 'sql_df' or 'applications_df' is not available or is empty. Skipping Photon analysis.\")\n",
    "        print(\"⚠️ 'sql_df' or 'applications_df' is not available or is empty. Skipping Photon analysis.\")\n",
    "\n",
    "except NameError as ne:\n",
    "    logger.error(\"❌ A required DataFrame ('sql_df' or 'applications_df') was not found. Please ensure the main analysis has been run successfully.\", exc_info=True)\n",
    "    print(\"❌ A required DataFrame ('sql_df' or 'applications_df') was not found. Please ensure the main analysis has been run successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(\"❌ An unexpected error occurred during Photon analysis: %s\", str(e), exc_info=True)\n",
    "    print(f\"❌ An unexpected error occurred during Photon analysis: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "emr_photon_analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}